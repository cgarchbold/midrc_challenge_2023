{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from midrc_dataset import midrc_challenge_dataset,midrc_challenge_dicom\n",
    "import plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import torchvision\n",
    "from get_model import create_model\n",
    "#from config import config\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Example usage of the dataset class\n",
    "root_dir = 'C:\\\\Users\\\\CGarc\\\\University of Kentucky\\\\Ahamed, Md. Atik - COVID severity\\\\data\\\\resized_224X224'\n",
    "\n",
    "annotations_file = 'MIDRC mRALE Mastermind Training Annotations_2079_20230428.csv'\n",
    "\n",
    "root_dir = '../data/resized_512X512'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                transforms.RandomRotation(20),                           # Randomly rotate the image within -20 to +20 degrees\n",
    "                transforms.RandomHorizontalFlip(0.1),                    # Randomly flip the image horizontally\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "\n",
    "dataset = midrc_challenge_dataset(root_dir, annotations_file,transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m i,data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataset):\n\u001b[0;32m      2\u001b[0m     image, score \u001b[39m=\u001b[39m data\n\u001b[0;32m      4\u001b[0m     plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m,\u001b[39m10\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\CGarc\\University of Kentucky\\Ahamed, Md. Atik - COVID severity\\code\\midrc_dataset.py:49\u001b[0m, in \u001b[0;36mmidrc_challenge_dataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     46\u001b[0m image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(fp)\n\u001b[0;32m     48\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform:\n\u001b[1;32m---> 49\u001b[0m     image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(image)\n\u001b[0;32m     51\u001b[0m \u001b[39mreturn\u001b[39;00m image, score\n",
      "File \u001b[1;32mc:\\Users\\CGarc\\anaconda3\\envs\\mrale\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\CGarc\\anaconda3\\envs\\mrale\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\CGarc\\anaconda3\\envs\\mrale\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:1379\u001b[0m, in \u001b[0;36mRandomRotation.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m   1376\u001b[0m         fill \u001b[39m=\u001b[39m [\u001b[39mfloat\u001b[39m(f) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m fill]\n\u001b[0;32m   1377\u001b[0m angle \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdegrees)\n\u001b[1;32m-> 1379\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mrotate(img, angle, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minterpolation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpand, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcenter, fill)\n",
      "File \u001b[1;32mc:\\Users\\CGarc\\anaconda3\\envs\\mrale\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1129\u001b[0m, in \u001b[0;36mrotate\u001b[1;34m(img, angle, interpolation, expand, center, fill)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m   1128\u001b[0m     pil_interpolation \u001b[39m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[1;32m-> 1129\u001b[0m     \u001b[39mreturn\u001b[39;00m F_pil\u001b[39m.\u001b[39mrotate(img, angle\u001b[39m=\u001b[39mangle, interpolation\u001b[39m=\u001b[39mpil_interpolation, expand\u001b[39m=\u001b[39mexpand, center\u001b[39m=\u001b[39mcenter, fill\u001b[39m=\u001b[39mfill)\n\u001b[0;32m   1131\u001b[0m center_f \u001b[39m=\u001b[39m [\u001b[39m0.0\u001b[39m, \u001b[39m0.0\u001b[39m]\n\u001b[0;32m   1132\u001b[0m \u001b[39mif\u001b[39;00m center \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\CGarc\\anaconda3\\envs\\mrale\\Lib\\site-packages\\torchvision\\transforms\\_functional_pil.py:312\u001b[0m, in \u001b[0;36mrotate\u001b[1;34m(img, angle, interpolation, expand, center, fill)\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimg should be PIL Image. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(img)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    311\u001b[0m opts \u001b[39m=\u001b[39m _parse_fill(fill, img)\n\u001b[1;32m--> 312\u001b[0m \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39mrotate(angle, interpolation, expand, center, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mopts)\n",
      "File \u001b[1;32mc:\\Users\\CGarc\\anaconda3\\envs\\mrale\\Lib\\site-packages\\PIL\\Image.py:2342\u001b[0m, in \u001b[0;36mImage.rotate\u001b[1;34m(self, angle, resample, expand, center, translate, fillcolor)\u001b[0m\n\u001b[0;32m   2339\u001b[0m     matrix[\u001b[39m2\u001b[39m], matrix[\u001b[39m5\u001b[39m] \u001b[39m=\u001b[39m transform(\u001b[39m-\u001b[39m(nw \u001b[39m-\u001b[39m w) \u001b[39m/\u001b[39m \u001b[39m2.0\u001b[39m, \u001b[39m-\u001b[39m(nh \u001b[39m-\u001b[39m h) \u001b[39m/\u001b[39m \u001b[39m2.0\u001b[39m, matrix)\n\u001b[0;32m   2340\u001b[0m     w, h \u001b[39m=\u001b[39m nw, nh\n\u001b[1;32m-> 2342\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(\n\u001b[0;32m   2343\u001b[0m     (w, h), Transform\u001b[39m.\u001b[39mAFFINE, matrix, resample, fillcolor\u001b[39m=\u001b[39mfillcolor\n\u001b[0;32m   2344\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\CGarc\\anaconda3\\envs\\mrale\\Lib\\site-packages\\PIL\\Image.py:2713\u001b[0m, in \u001b[0;36mImage.transform\u001b[1;34m(self, size, method, data, resample, fill, fillcolor)\u001b[0m\n\u001b[0;32m   2709\u001b[0m         im\u001b[39m.\u001b[39m__transformer(\n\u001b[0;32m   2710\u001b[0m             box, \u001b[39mself\u001b[39m, Transform\u001b[39m.\u001b[39mQUAD, quad, resample, fillcolor \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2711\u001b[0m         )\n\u001b[0;32m   2712\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2713\u001b[0m     im\u001b[39m.\u001b[39m__transformer(\n\u001b[0;32m   2714\u001b[0m         (\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39m+\u001b[39m size, \u001b[39mself\u001b[39m, method, data, resample, fillcolor \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2715\u001b[0m     )\n\u001b[0;32m   2717\u001b[0m \u001b[39mreturn\u001b[39;00m im\n",
      "File \u001b[1;32mc:\\Users\\CGarc\\anaconda3\\envs\\mrale\\Lib\\site-packages\\PIL\\Image.py:2789\u001b[0m, in \u001b[0;36mImage.__transformer\u001b[1;34m(self, box, image, method, data, resample, fill)\u001b[0m\n\u001b[0;32m   2786\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m Use \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(filters[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m or \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m filters[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m   2787\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m-> 2789\u001b[0m image\u001b[39m.\u001b[39mload()\n\u001b[0;32m   2791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload()\n\u001b[0;32m   2793\u001b[0m \u001b[39mif\u001b[39;00m image\u001b[39m.\u001b[39mmode \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mP\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\CGarc\\anaconda3\\envs\\mrale\\Lib\\site-packages\\PIL\\ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(msg)\n\u001b[0;32m    268\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[1;32m--> 269\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39mdecode(b)\n\u001b[0;32m    270\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    271\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i,data in enumerate(dataset):\n",
    "    image, score = data\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow( image.permute(1, 2, 0), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    results_dir = os.path.join(\"plots\",\"high_res\")\n",
    "\n",
    "    if not os.path.isdir(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "\n",
    "    filename = os.path.join(\"plots\",\"high_res\",str(i)+\".png\")\n",
    "\n",
    "    plt.savefig(filename, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
