{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/spa-d2/grad/mah259/anaconda3/envs/research/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import cross_fold\n",
    "from midrc_dataset import midrc_challenge_dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import os\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from get_model import create_model\n",
    "from config import config\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs,model,device, train_loader, val_loader, criterion, optimizer, fold_number):\n",
    "    best_vloss = 1_000_000.\n",
    "    for e in range(epochs):\n",
    "        print('EPOCH {}:'.format(e + 1))\n",
    "        running_loss = 0.\n",
    "        last_loss = 0.\n",
    "        running_train_kappa=0.0\n",
    "        avg_train_kappa=0.0\n",
    "        model.train(True)\n",
    "\n",
    "        for i, data in enumerate(train_loader):\n",
    "            # Every data instance is an input + label pair\n",
    "            inputs, labels = data\n",
    "\n",
    "            # Zero your gradients for every batch!\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Make predictions for this batch\n",
    "            outputs = model(inputs.to(device))\n",
    "            labels=labels/24.0\n",
    "\n",
    "            # Compute the loss and its gradients\n",
    "            loss = criterion(outputs, labels.float().to(device).unsqueeze(1))\n",
    "            loss.backward()\n",
    "\n",
    "            # Adjust learning weights\n",
    "            optimizer.step()\n",
    "            outputs=outputs*24.0\n",
    "            labels=labels*24.0\n",
    "            \n",
    "            outputs=torch.round(outputs)\n",
    "            outputs=outputs.data.cpu().numpy()\n",
    "            \n",
    "            labels=labels.data.cpu().numpy()\n",
    "            outputs=outputs.flatten()\n",
    "            labels=labels.flatten()\n",
    "            kappa_score_train=cohen_kappa_score(labels,outputs,weights='quadratic')\n",
    "            running_train_kappa+=kappa_score_train\n",
    "            # Gather data and report\n",
    "            running_loss += loss.item()\n",
    "            # if i % 10 == 9:\n",
    "            #     last_loss = running_loss / 10 # loss per batch\n",
    "            #     print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            #     tb_x = e * len(train_loader) + i + 1\n",
    "            #     #tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            #     running_loss = 0.\n",
    "\n",
    "\n",
    "        \n",
    "        avg_loss = running_loss/(i+1)\n",
    "        avg_train_kappa=running_train_kappa/(i+1)\n",
    "\n",
    "        \n",
    "        running_vloss = 0.0\n",
    "        running_kappa = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(val_loader):\n",
    "                vinputs, vlabels = vdata\n",
    "                voutputs = model(vinputs.to(device))\n",
    "                vlabels=vlabels/24.0\n",
    "                vloss = criterion(voutputs, vlabels.float().to(device).unsqueeze(1))\n",
    "                voutputs=voutputs*24.0\n",
    "                vlabels=vlabels*24.0\n",
    "                voutputs=torch.round(voutputs)\n",
    "                voutputs=voutputs.data.cpu().numpy()\n",
    "                vlabels=vlabels.data.cpu().numpy()\n",
    "                voutputs=voutputs.flatten()\n",
    "                vlabels=vlabels.flatten()\n",
    "                kappa_score=cohen_kappa_score(vlabels,voutputs,weights='quadratic')\n",
    "                running_kappa+=kappa_score\n",
    "                running_vloss += vloss\n",
    "                \n",
    "\n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        avg_val_kappa= running_kappa / (i + 1)\n",
    "        \n",
    "        print('LOSS train {} valid {}, Kappa train {} valid {}'.format(avg_loss, avg_vloss,avg_train_kappa,avg_val_kappa))\n",
    "\n",
    "        # Track best performance, and save the model's state\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            model_path = os.path.join('models','modelsave_fold_{}'.format(fold_number))\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,device,dataloader):\n",
    "    with torch.no_grad():\n",
    "        squared_error = 0\n",
    "        absolute_error = 0\n",
    "\n",
    "        for data in dataloader:\n",
    "            inputs, labels = data\n",
    "\n",
    "            outputs = model(inputs.to(device))\n",
    "\n",
    "            squared_error += (outputs*torch.tensor(24.0).to(device) - labels.float().to(device).unsqueeze(1))**2\n",
    "            absolute_error += torch.abs(outputs*torch.tensor(24.0).to(device)-labels.float().to(device).unsqueeze(1))\n",
    "            \n",
    "        #returns mae and rmse\n",
    "        return absolute_error/len(dataloader), torch.sqrt(squared_error/len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1  Train Indices:  2078  Val indices:  520\n",
      "Fold:  2  Train Indices:  2096  Val indices:  502\n",
      "Fold:  3  Train Indices:  2050  Val indices:  548\n",
      "Fold:  4  Train Indices:  2072  Val indices:  526\n",
      "Fold:  5  Train Indices:  2096  Val indices:  502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/spa-d2/grad/mah259/anaconda3/envs/research/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/u/spa-d2/grad/mah259/anaconda3/envs/research/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "LOSS train 0.13785449859614557 valid 0.19194571673870087, Kappa train 0.05088007636145116 valid 0.2262654597842928\n",
      "EPOCH 2:\n",
      "LOSS train 0.10868135321025665 valid 0.11101017147302628, Kappa train 0.23276807193157145 valid 0.3584817337876917\n",
      "EPOCH 3:\n",
      "LOSS train 0.09946088733581396 valid 0.10054195672273636, Kappa train 0.30811323923124306 valid 0.5713177378350045\n",
      "EPOCH 4:\n",
      "LOSS train 0.08703128503492245 valid 0.16995783150196075, Kappa train 0.4428359642208689 valid 0.18090501423955607\n",
      "EPOCH 5:\n",
      "LOSS train 0.0732894787994715 valid 0.08643194288015366, Kappa train 0.5457211607134518 valid 0.6296977552879096\n",
      "EPOCH 6:\n",
      "LOSS train 0.07492348213608448 valid 0.07981036603450775, Kappa train 0.5403113404015518 valid 0.6022760100715193\n",
      "EPOCH 7:\n",
      "LOSS train 0.0700666304391164 valid 0.06076836213469505, Kappa train 0.5776868066204335 valid 0.7028635160028557\n",
      "EPOCH 8:\n",
      "LOSS train 0.06624685563147067 valid 0.06850048154592514, Kappa train 0.5988265552265201 valid 0.643672926691326\n",
      "EPOCH 9:\n",
      "LOSS train 0.06350646443091906 valid 0.05163513123989105, Kappa train 0.6217835372827308 valid 0.7305044866935239\n",
      "EPOCH 10:\n",
      "LOSS train 0.060863589595716736 valid 0.1261562705039978, Kappa train 0.646307790731631 valid 0.44216527260265304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/spa-d2/grad/mah259/anaconda3/envs/research/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/u/spa-d2/grad/mah259/anaconda3/envs/research/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "LOSS train 0.1327347114454699 valid 0.0998387336730957, Kappa train 0.23730905032110844 valid 0.25414347589391056\n",
      "EPOCH 2:\n",
      "LOSS train 0.11118936757663735 valid 0.08794699609279633, Kappa train 0.31514419386892345 valid 0.30604073561500156\n",
      "EPOCH 3:\n",
      "LOSS train 0.09659040395085139 valid 0.08613785356283188, Kappa train 0.45000088695135204 valid 0.34977610313280416\n",
      "EPOCH 4:\n",
      "LOSS train 0.08062073895494447 valid 0.06834349781274796, Kappa train 0.5549364350915202 valid 0.4858225900425834\n",
      "EPOCH 5:\n",
      "LOSS train 0.07191210838731464 valid 0.0590057298541069, Kappa train 0.6115503080170187 valid 0.5512690328978143\n",
      "EPOCH 6:\n",
      "LOSS train 0.06452819740556123 valid 0.06601826101541519, Kappa train 0.6581815709818674 valid 0.5924885038302788\n",
      "EPOCH 7:\n",
      "LOSS train 0.06572264226736459 valid 0.06739597767591476, Kappa train 0.6574133293109627 valid 0.580669697205147\n",
      "EPOCH 8:\n",
      "LOSS train 0.06252951524753607 valid 0.060270700603723526, Kappa train 0.6687709811311452 valid 0.6245200724204927\n",
      "EPOCH 9:\n",
      "LOSS train 0.06076098957191442 valid 0.05738629400730133, Kappa train 0.678523331958543 valid 0.6367547953009781\n",
      "EPOCH 10:\n",
      "LOSS train 0.05728689121892889 valid 0.054865024983882904, Kappa train 0.6978322282321466 valid 0.6452526762224091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/spa-d2/grad/mah259/anaconda3/envs/research/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/u/spa-d2/grad/mah259/anaconda3/envs/research/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "LOSS train 0.13026717934728593 valid 0.12379279732704163, Kappa train 0.17518904472408814 valid 0.3613283864388003\n",
      "EPOCH 2:\n",
      "LOSS train 0.11075745187988577 valid 0.13864833116531372, Kappa train 0.267833628170497 valid 0.2414199204470281\n",
      "EPOCH 3:\n",
      "LOSS train 0.09464935582968616 valid 0.19056332111358643, Kappa train 0.3865706666765274 valid 0.17929697894263766\n",
      "EPOCH 4:\n",
      "LOSS train 0.09306003491199294 valid 0.10279406607151031, Kappa train 0.4097924810009442 valid 0.3506767227352909\n",
      "EPOCH 5:\n",
      "LOSS train 0.07979222937205503 valid 0.09775731712579727, Kappa train 0.5100257230622234 valid 0.4156204749583088\n",
      "EPOCH 6:\n",
      "LOSS train 0.07285419928790755 valid 0.10163211077451706, Kappa train 0.55008896812897 valid 0.5628404244877669\n",
      "EPOCH 7:\n",
      "LOSS train 0.07049975789679114 valid 0.05844782292842865, Kappa train 0.5750111376047566 valid 0.655117729575568\n",
      "EPOCH 8:\n",
      "LOSS train 0.06707545121510823 valid 0.0697299912571907, Kappa train 0.6069220993493246 valid 0.6423134903980076\n",
      "EPOCH 9:\n",
      "LOSS train 0.06911527891029683 valid 0.08131865411996841, Kappa train 0.5887753041549572 valid 0.5708920478914183\n",
      "EPOCH 10:\n",
      "LOSS train 0.0606970480072868 valid 0.07250257581472397, Kappa train 0.6391667218592384 valid 0.6475219984775207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/spa-d2/grad/mah259/anaconda3/envs/research/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/u/spa-d2/grad/mah259/anaconda3/envs/research/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "\n",
    "folds = cross_fold.create_folded_datasets(\"../data/resized_224X224/label_info/labels.json\")\n",
    "\n",
    "root_dir = '../data/resized_224X224'\n",
    "\n",
    "annotations_file = 'MIDRC mRALE Mastermind Training Annotations_2079_20230428.csv'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size = 16\n",
    "epochs = config['epochs']\n",
    "\n",
    "\n",
    "if config['augment']:\n",
    "    # Define the transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomRotation(10),                           # Randomly rotate the image within -10 to +10 degrees\n",
    "        transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),# Randomly crop and resize the image to 224x224 pixels\n",
    "        transforms.RandomHorizontalFlip(),                       # Randomly flip the image horizontally\n",
    "        transforms.RandomApply([transforms.Lambda(lambda img: \n",
    "                                                  F.adjust_brightness(img, brightness_factor=torch.rand(1).item() + 0.5))], \n",
    "                                                  p=0.5),  # Random brightness adjustment\n",
    "        transforms.ToTensor(),                                   # Convert the image to a tensor\n",
    "        # TODO:Normalization?\n",
    "    ])\n",
    "else:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        # TODO:Normalization?\n",
    "    ])\n",
    "\n",
    "val_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "\n",
    "for f_i,fold in enumerate(folds):\n",
    "    print(\"FOLD: \",f_i+1)\n",
    "    train_list, val_list = fold\n",
    "\n",
    "    model = create_model(config=config)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    train_dataset = midrc_challenge_dataset(root_dir, annotations_file, transform, fp_list = train_list)\n",
    "    val_dataset = midrc_challenge_dataset(root_dir, annotations_file, val_transform, fp_list = val_list)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=True)\n",
    "\n",
    "    #Training per fold\n",
    "    train(epochs,model,device,train_loader,val_loader, criterion, optimizer, f_i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1  MAE: 5.070911407470703  RMSE:  6.121790885925293\n",
      "Fold:  2  MAE: 5.229495525360107  RMSE:  6.513065814971924\n",
      "Fold:  3  MAE: 4.875302791595459  RMSE:  6.091127872467041\n",
      "Fold:  4  MAE: 5.047328472137451  RMSE:  6.208610534667969\n",
      "Fold:  5  MAE: 4.741214752197266  RMSE:  6.251406192779541\n"
     ]
    }
   ],
   "source": [
    "#Testing Loop\n",
    "for f_i,fold in enumerate(folds):\n",
    "\n",
    "    train_list, val_list = fold\n",
    "\n",
    "    val_dataset = midrc_challenge_dataset(root_dir, annotations_file, val_transform, fp_list = val_list)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = 1, shuffle=True)\n",
    "\n",
    "    model = create_model()\n",
    "    model_pth = os.path.join('models','modelsave_fold_{}'.format(f_i))\n",
    "    model.load_state_dict(torch.load(model_pth))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    avg_mae, avg_rmse = test(model,device,val_loader)\n",
    "\n",
    "    print(\"Fold: \",f_i+1, \" MAE:\", avg_mae.item() , \" RMSE: \", avg_rmse.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrale",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
